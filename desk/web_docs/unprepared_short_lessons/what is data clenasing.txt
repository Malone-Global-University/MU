What Is Data Cleansing?
Data cleansing is an essential process for preparing raw data for machine learning (ML) and business intelligence (BI) applications. Raw data may contain numerous errors, which can affect the accuracy of ML models and lead to incorrect predictions and negative business impact. 

Key steps of data cleansing include modifying and removing incorrect and incomplete data fields, identifying and removing duplicate information and unrelated data, and correcting formatting, missing values, and spelling errors.

Why Is Data Cleansing Important?
When a company uses data to drive decision-making, it's crucial they use relevant, complete, and accurate data. However, datasets often contain errors that must be removed before analysis. They may include formatting errors such as incorrectly written dates and monetary and other units of measure that may significantly impact predictions. Outliers are a particular concern as they invariably skew results. Other data errors commonly found include corrupted data points, missing information, and typographical errors. Clean data can help with highly accurate ML models. 

Clean and accurate data is particularly crucial for training ML models, as using poor training datasets can result in erroneous predictions in deployed models. This is the primary reason data scientists spend such a high proportion of their time preparing data for ML.

How Do You Validate Your Data is Clean?
The data cleansing process entails several steps to identify and fix problem entries. The first step is to analyze the data to identify errors. This may involve using qualitative analysis tools that use rules, patterns, and constraints to identify invalid values. The next step is to remove or correct errors. 

Common data cleaning steps include remediating:

Duplicate data: Drop duplicate information
Irrelevant data: Identify critical fields for the particular analysis and drop irrelevant data from the analysis
Outliers: Outliers can dramatically affect model performance, so identify outliers and determine appropriate action
Missing data: Flag and drop or impute missing data
Structural errors: Correct typographical errors and other inconsistencies, and make data conform to a common pattern or convention